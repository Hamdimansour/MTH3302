{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MTH3302 : Méthodes probabilistes et statistiques pour l'I.A.\n",
    "\n",
    "Jonathan Jalbert<br/>\n",
    "Professeur adjoint au Département de mathématiques et de génie industriel<br/>\n",
    "Polytechnique Montréal<br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# TD 9 : Théorie de l'information\n",
    "___\n",
    "\n",
    "### Description\n",
    "\n",
    "Dans ce travail dirigé, vous aurez l'occasion de déterminer quels mots sont les plus discriminants pour la construction du filtre anti-spam du TD8.\n",
    "\n",
    "L'exercice 1 vous permettra de programmer les fonctions utiles pour classer les mots en fonction de leur information mutuelle avec la catégorie du message (courriel ou pourriel). L'exercice 2 vous permettra d'estimer la loi conjointe et les lois marginales entre une variable explicative $X_j$ et $Y$ avec les messages électroniques obtenus. Dans l'exercice 3, vous identifierez les mots les plus discriminant pour classer les messages électroniques en courriel ou pourriel.\n",
    "\n",
    "### Données\n",
    "\n",
    "Les données exploitées dans ce TD correspondent à des messages électroniques authentiques d'un employé de la compagnie Enron. Vous pouvez télécharger le jeux de données à partir du site web du cours. Le fichier doit être décompressé dans un dossier nommé *data* du répertoire courant de votre calepin Jupyter. \n",
    "\n",
    "Ces données ont déjà été utilisées dans le TD8. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics, DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préliminaires\n",
    "\n",
    "Cette section permet de dénombrer le nombre de courriels et de pourriels contenant chacun des mots répertoriés. Les deux dictionnaires suivants sont retournés :\n",
    "- ham_wordcounts\n",
    "- spam_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "wordlisting : Cette fonction transforme un fichier texte en une liste de mots. Le nombre de fois que\n",
    "              les mots apparaîssent ne sont pas répertorié.\n",
    "Input: filename::String le chemin du fichier texte \n",
    "Output: Array{Sting} Liste des mots contenus dans le fichier texte\n",
    "\"\"\"\n",
    "\n",
    "function wordlisting(filename::String)\n",
    "    \n",
    "    f = read(filename, String)\n",
    "    text = replace(f, r\"[0123456789]\" => \"\")\n",
    "    words = split(text, r\"\\W+\")\n",
    "    filter!(x -> length(x) > 1, words)\n",
    "    wordlist = unique(words)\n",
    "    \n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "wordcounting : À partir d'un Array of Array contenant la liste des mots d'un ensemble de fichiers texte, la fonction \n",
    "               retourne le nombre de fois où chaque mot est présent.\n",
    "Input: Un array correspondant à la liste des mots pour chacun des fichiers texte \n",
    "Output: Dictionnaire compilant le nombre de ligne dans lesquelles chacun des mots apparaît.\n",
    "\"\"\"\n",
    "\n",
    "function wordcounting(A::Array{Array{SubString{String},1},1})\n",
    "   \n",
    "    words = vcat(A...)\n",
    "\n",
    "    wordcounts = Dict{String,Int64}()\n",
    "\n",
    "    for word in words\n",
    "        wordcounts[word]=get(wordcounts, word, 0) + 1\n",
    "    end\n",
    "    \n",
    "    return wordcounts\n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "# Récupération des noms de fichier de tous les hams\n",
    "filesdir = \"../Exercices/Ressources/enron1/ham/\"\n",
    "filename_ham = filesdir.*readdir(filesdir)\n",
    "\n",
    "# Récupération des noms de fichier de tous les spams\n",
    "filesdir = \"../Exercices/Ressources/enron1/spam/\"\n",
    "filename_spam = filesdir.*readdir(filesdir)\n",
    "\n",
    "ham_wordlist = wordlisting.(filename_ham)\n",
    "ham_wordcounts = wordcounting(ham_wordlist)\n",
    "\n",
    "spam_wordlist = wordlisting.(filename_spam)\n",
    "spam_wordcounts = wordcounting(spam_wordlist);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1\n",
    "\n",
    "Programmation des fonctions utiles en théorie de l'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Entropie \n",
    "\n",
    "Programmez une fonction permettant de calculer l'entropie d'une variable aléatoire catégorielle $Y$ ayant comme argument le vecteur de probabilités des résulats possibles de $Y$.\n",
    "\n",
    "Testez votre fonction de la façon suivante :\n",
    "\n",
    "`p = [1/4,1/4,1/4,1/4]`\n",
    "\n",
    "`entropy(p)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function log2_2(x)\n",
    "    x > 0 ? log2(x) : 0\n",
    "end\n",
    "function entropy(p::Vector{<:Real})\n",
    "    return -log2_2.(p)'*p\n",
    "end\n",
    "p = [1/4,1/4,1/4,1/4]\n",
    "entropy(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Entropie croisée\n",
    "\n",
    "Programmez une fonction permettant de calculer l'entropie croisée d'une variable aléatoire catégorielle $Y$ ayant comme argument sont vecteur de probabilités des résulats possibles et comme deuxième argument la second vecteur de probabité correspondant à une autre fonction de masse pour $Y.\n",
    "\n",
    "Testez votre fonction de la façon suivante :\n",
    "\n",
    "`p = [1/2,1/4,1/8,1/8]`\n",
    "\n",
    "`q = [1/4,1/4,1/4,1/4]`\n",
    "\n",
    "`crossentropy(p,q)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function crossentropy(p::Vector{<:Real},q::Vector{<:Real})\n",
    "    -log2.(q)'*p\n",
    "end\n",
    "p = [1/2,1/4,1/8,1/8]\n",
    "q = [1/4,1/4,1/4,1/4]\n",
    "crossentropy(p,q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Divergence de Kullback-Leibler\n",
    "\n",
    "Programmez une fonction permettant de calculer la divergence de Kullback-Leibler entre les deux fonctions de masse caractérisées par les vecteurs de probabilités $p$ et $q$.\n",
    "\n",
    "Testez votre fonction de la façon suivante :\n",
    "\n",
    "`p = [1/2,1/4,1/8,1/8]`\n",
    "\n",
    "`q = [1/4,1/4,1/4,1/4]`\n",
    "\n",
    "`crossentropy(p,q)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function kullback(p::Vector{<:Real}, q::Vector{<:Real})\n",
    "       -entropy(p)+crossentropy(p,q)\n",
    "end\n",
    "p = [1/2,1/4,1/8,1/8]\n",
    "q = [1/4,1/4,1/4,1/4]\n",
    "kullback(p,q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 \n",
    "\n",
    "Estimation des lois conjointes et marginales des variables $X$ et $Y$ avec le jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Soit le mot *enron*, construisez le tableau des fréquences observées de la variable $X$ et $Y$.\n",
    "\n",
    "Ce tableau des fréquences observées est illustré à l'exemple 8 du Chapitre 9 des notes de cours. Servez vous des dictionnaires ham_wordcounts et spam_wordcounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 1500.0  2210.0\n",
       "    0.0  1462.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mot = \"enron\"\n",
    "freq = zeros(2,2)\n",
    "# À COMPLÉTER\n",
    "freq[2,1] = count(in.(\"enron\", spam_wordlist))\n",
    "freq[2,2] = count(in.(\"enron\", ham_wordlist))\n",
    "freq[1,1] = length(filename_spam) - freq[2,1]\n",
    "freq[1,2] = length(filename_ham) - freq[2,2]\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Avec le tableau des fréquences observées, estimez la loi de probabilité conjointe de $X$ et $Y$.\n",
    "\n",
    "Produisez un vecteur de probabilités représentant les 4 possibilités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.290023  0.427301\n",
       " 0.0       0.282676"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = (length(filename_spam)+length(filename_ham))\n",
    "prob_conj = freq./n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Avec le tableau des fréquences observées, estimez la loi de probabilité conjointe de $X$ et $Y$ estimée à l'aide du produit des lois marginales.\n",
    "\n",
    "Produisez un vecteur de probabilités représentant les 4 possibilités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.208041   0.509283\n",
       " 0.0819826  0.200693"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_marg = freq*ones(2,2)*freq./(n^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Estimez l'information mutuelle entre $X$ et $Y$.\n",
    "\n",
    "Utilisez la loi conjointe estimée et le produit des lois marginales estimées dans la divergence de Kullback-Leibler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17049542401082207"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kullback(reshape(prob_conj, 4,1)[:,1], reshape(prob_marg, 4,1)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3\n",
    "\n",
    "Identification des mots les plus discriminants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) En reprenant la méthode de l'exercice 2, calculez l'information mutuelle pour tous les mots contenus dans les messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calc_score (generic function with 1 method)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calc_score(mot)\n",
    "    F = zeros(2,2)\n",
    "    F[2,1] = count(in.(mot, spam_wordlist))\n",
    "    F[2,2] = count(in.(mot, ham_wordlist))\n",
    "    F[1,1] = length(filename_spam) - F[2,1]\n",
    "    F[1,2] = length(filename_ham) - F[2,2]\n",
    "    prob_conj = F./n\n",
    "    prob_marg = F*ones(2,2)*F./(n^2)\n",
    "    return kullback(reshape(prob_conj, 4,1)[:,1], reshape(prob_marg, 4,1)[:,1])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: filenames not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: filenames not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[94]:1"
     ]
    }
   ],
   "source": [
    "ham_words = collect(keys(ham_wordcounts))\n",
    "scores = Dict(words .=> calc_score.(ham_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_words = collect(keys(spam_wordcounts))\n",
    "for spam_word in spam_words\n",
    "    if ! (spam_word in words)\n",
    "        scores[spam_word] = calc_score(spam_word)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Selon l'information mutuelle, quels sont les 10 mots les plus dépendants de $Y$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(word = collect(keys(scores)), score = collect(values(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>word</th><th>score</th></tr><tr><th></th><th>String</th><th>Float64</th></tr></thead><tbody><p>16,204 rows × 2 columns</p><tr><th>1</th><td>Subject</td><td>NaN</td></tr><tr><th>2</th><td>enron</td><td>0.170495</td></tr><tr><th>3</th><td>cc</td><td>0.131203</td></tr><tr><th>4</th><td>hpl</td><td>0.121008</td></tr><tr><th>5</th><td>daren</td><td>0.112389</td></tr><tr><th>6</th><td>http</td><td>0.100842</td></tr><tr><th>7</th><td>gas</td><td>0.0989163</td></tr><tr><th>8</th><td>forwarded</td><td>0.0954772</td></tr><tr><th>9</th><td>pm</td><td>0.0934839</td></tr><tr><th>10</th><td>ect</td><td>0.090351</td></tr><tr><th>11</th><td>hou</td><td>0.0896125</td></tr><tr><th>12</th><td>thanks</td><td>0.0881384</td></tr><tr><th>13</th><td>subject</td><td>0.0817732</td></tr><tr><th>14</th><td>meter</td><td>0.0813543</td></tr><tr><th>15</th><td>attached</td><td>0.0770872</td></tr><tr><th>16</th><td>deal</td><td>0.0724497</td></tr><tr><th>17</th><td>am</td><td>0.0715992</td></tr><tr><th>18</th><td>farmer</td><td>0.0590805</td></tr><tr><th>19</th><td>your</td><td>0.058139</td></tr><tr><th>20</th><td>nom</td><td>0.0562176</td></tr><tr><th>21</th><td>corp</td><td>0.0546882</td></tr><tr><th>22</th><td>more</td><td>0.0540639</td></tr><tr><th>23</th><td>mmbtu</td><td>0.0536875</td></tr><tr><th>24</th><td>xls</td><td>0.0511931</td></tr><tr><th>25</th><td>here</td><td>0.049778</td></tr><tr><th>26</th><td>let</td><td>0.044309</td></tr><tr><th>27</th><td>volumes</td><td>0.0440113</td></tr><tr><th>28</th><td>questions</td><td>0.0422104</td></tr><tr><th>29</th><td>www</td><td>0.041936</td></tr><tr><th>30</th><td>sitara</td><td>0.0406248</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& word & score\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & Subject & NaN \\\\\n",
       "\t2 & enron & 0.170495 \\\\\n",
       "\t3 & cc & 0.131203 \\\\\n",
       "\t4 & hpl & 0.121008 \\\\\n",
       "\t5 & daren & 0.112389 \\\\\n",
       "\t6 & http & 0.100842 \\\\\n",
       "\t7 & gas & 0.0989163 \\\\\n",
       "\t8 & forwarded & 0.0954772 \\\\\n",
       "\t9 & pm & 0.0934839 \\\\\n",
       "\t10 & ect & 0.090351 \\\\\n",
       "\t11 & hou & 0.0896125 \\\\\n",
       "\t12 & thanks & 0.0881384 \\\\\n",
       "\t13 & subject & 0.0817732 \\\\\n",
       "\t14 & meter & 0.0813543 \\\\\n",
       "\t15 & attached & 0.0770872 \\\\\n",
       "\t16 & deal & 0.0724497 \\\\\n",
       "\t17 & am & 0.0715992 \\\\\n",
       "\t18 & farmer & 0.0590805 \\\\\n",
       "\t19 & your & 0.058139 \\\\\n",
       "\t20 & nom & 0.0562176 \\\\\n",
       "\t21 & corp & 0.0546882 \\\\\n",
       "\t22 & more & 0.0540639 \\\\\n",
       "\t23 & mmbtu & 0.0536875 \\\\\n",
       "\t24 & xls & 0.0511931 \\\\\n",
       "\t25 & here & 0.049778 \\\\\n",
       "\t26 & let & 0.044309 \\\\\n",
       "\t27 & volumes & 0.0440113 \\\\\n",
       "\t28 & questions & 0.0422104 \\\\\n",
       "\t29 & www & 0.041936 \\\\\n",
       "\t30 & sitara & 0.0406248 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "16204×2 DataFrame\n",
       "│ Row   │ word          │ score      │\n",
       "│       │ \u001b[90mString\u001b[39m        │ \u001b[90mFloat64\u001b[39m    │\n",
       "├───────┼───────────────┼────────────┤\n",
       "│ 1     │ Subject       │ NaN        │\n",
       "│ 2     │ enron         │ 0.170495   │\n",
       "│ 3     │ cc            │ 0.131203   │\n",
       "│ 4     │ hpl           │ 0.121008   │\n",
       "│ 5     │ daren         │ 0.112389   │\n",
       "│ 6     │ http          │ 0.100842   │\n",
       "│ 7     │ gas           │ 0.0989163  │\n",
       "│ 8     │ forwarded     │ 0.0954772  │\n",
       "│ 9     │ pm            │ 0.0934839  │\n",
       "│ 10    │ ect           │ 0.090351   │\n",
       "⋮\n",
       "│ 16194 │ shortcut      │ 8.84122e-8 │\n",
       "│ 16195 │ actively      │ 8.84122e-8 │\n",
       "│ 16196 │ regardless    │ 4.40636e-8 │\n",
       "│ 16197 │ fri           │ 4.40636e-8 │\n",
       "│ 16198 │ normally      │ 4.40636e-8 │\n",
       "│ 16199 │ technical     │ 4.40636e-8 │\n",
       "│ 16200 │ unfortunately │ 4.40636e-8 │\n",
       "│ 16201 │ buddy         │ 4.40636e-8 │\n",
       "│ 16202 │ processing    │ 2.95335e-8 │\n",
       "│ 16203 │ continued     │ 7.83285e-9 │\n",
       "│ 16204 │ them          │ 0.0        │"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort!(df, [:score], rev = true);\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
